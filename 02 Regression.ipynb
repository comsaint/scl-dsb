{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Supervised Learning - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "1. Demonstrate the workflow of a machine learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap\n",
    "-----------\n",
    "1. **Supervised learning** is a category of machine learning which focus on getting accurate prediction (class / number), given training data (a matrix of examples and desired output).\n",
    "2. If the desired output (called \"label\" or \"target\" in machine learning terminology) is a continous number, e.g. price, temperature, stock index... then it is called a **Regression** problem\n",
    "3. Usually, the data is given in as a n \\* m matrix, where each row is an example/sample and each column is a property of the sample (called *feature*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# Load some packages and settings\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "rnd = 1\n",
    "np.random.seed(rnd)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"1\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and take a look at our data again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 10)\n"
     ]
    }
   ],
   "source": [
    "HOUSING_PATH = os.path.join(\"data\", \"housing\")  # path of the data\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()  # Load data\n",
    "print(housing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows of data\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix `housing` now holds our data - you can see each row is one example, and each column describes the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are to predict, the `median_house_value`, let's take it out so the features `longitude`, `median_income` etc. are stored in a variable X,\n",
    "\n",
    "and the target `median_house_value` stored in variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.drop('median_house_value', axis=1)  # the features\n",
    "y = housing['median_house_value']  # the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training set, Validation set and Test set\n",
    "\n",
    "Before we dive in, there is a very important step to do: let's split the data set into 2, one for training the model (commonly called the * *training set* *) and the other for evaluation (the * *test set* *).\n",
    "\n",
    "This is **VERY IMPORTANT** in modeling - we need to hold out a set of data, which is not known by the model, to evaluate how well the model perform.\n",
    "This data set is called the **test set**.\n",
    "\n",
    "An analogue, in school - we are *__trained__* with materials in lessons (reading, lectures...). To evaluate how well we understand the materials, we are *__tested__* in with materials that are relevant, but not known in advance (i.e. examination). Otherwise we will simply recite (* *memorize* *) the questions and answers in exam and get a good score, without actually understand the materials at all!\n",
    "\n",
    "### Question: what problem will it pose if a model has access to the test data during training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18576 2064\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we will use `X_train` and `y_train` for training the model (i.e. tune the parameters of the model), and **leave the test set `X_test` `y_test` untouched** until we are done with modelling.\n",
    "\n",
    "Again, **NEVER TUNE YOUR MODEL WITH THE TEST SET!** It should only be used for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start simple, let's pick **1** feature with highest correlation to the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_income         0.687827\n",
       "latitude              0.141070\n",
       "total_rooms           0.134944\n",
       "housing_median_age    0.102239\n",
       "households            0.065731\n",
       "total_bedrooms        0.050145\n",
       "longitude             0.047969\n",
       "population            0.025464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute correlation, take absolute, and sort in descending order\n",
    "abs(X_train.corrwith(y_train)).sort_values(ascending=False)  # the highest one is \"median_income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick `median_income` as the only feature\n",
    "X_train_1 = X_train['median_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the error metric (in this case the mean squared error, MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# pick a model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train_1 = np.array(X_train_1).reshape(-1, 1)  # preparing feature (data X)\n",
    "#train_set_univariate__y = train_set_univariate['median_house_value']  # preparing the target (y)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X=X_train_1, y=y_train)  # feed X and y into the linear model, ask it to 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope `m`: 41,754.99\n",
      "Intercept `c`: 45,400.46\n"
     ]
    }
   ],
   "source": [
    "print(\"Slope `m`: {:,.2f}\\nIntercept `c`: {:,.2f}\".format(linear_reg.coef_[0], linear_reg.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in training set:\n",
      "Average target in train set: 207,202\n",
      "Mean Absolute Error on train set: 62,644\n",
      "Root Mean Squared Error on train set: 83,711\n",
      "Relative Root Mean Squared Error on train set: 40.40 %\n",
      "R^2 of train set: 0.47\n"
     ]
    }
   ],
   "source": [
    "# get predictions for validation set\n",
    "y_pred_train = linear_reg.predict(np.array(X_train_1).reshape(-1, 1))\n",
    "\n",
    "# evaluate with the Validation set\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_eval(y_true, y_pred):\n",
    "    print('Average target in train set: {:,.0f}'.format(y_true.mean()))\n",
    "    print('Mean Absolute Error on train set: {:,.0f}'.format(metrics.mean_absolute_error(y_true, y_pred)))\n",
    "    print('Root Mean Squared Error on train set: {:,.0f}'.format(np.sqrt(metrics.mean_squared_error(y_true, y_pred))))\n",
    "    print('Relative Root Mean Squared Error on train set: {:.2f} %'.format(100 * np.sqrt(metrics.mean_squared_error(y_true, y_pred))/y_true.mean()))\n",
    "    print('R^2 of train set: {:,.2f}'.format(metrics.r2_score(y_true, y_pred)))\n",
    "    return None\n",
    "\n",
    "print(\"Error in training set:\")\n",
    "print_eval(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that the error (RMSE) is quite high (84K, or 40.4%). How can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Improve model performance\n",
    "\n",
    "There are many ways to optimize a model's performance:\n",
    "1. Try different models\n",
    "2. Build an ensemble of models\n",
    "3. Better feature engineering\n",
    "4. Obtain more data\n",
    "\n",
    "Let's look at these approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Try different models\n",
    "\n",
    "There are a lot of models frequently come up in machine learning, one of them being the family of **Decision Tree**.\n",
    "\n",
    "Let's try on our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "# train the model on 1 feature\n",
    "tree_reg.fit(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in training set:\n",
      "Average target in train set: 207,202\n",
      "Mean Absolute Error on train set: 25,362\n",
      "Root Mean Squared Error on train set: 48,588\n",
      "Relative Root Mean Squared Error on train set: 23.45 %\n",
      "R^2 of train set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# evaluate on train set\n",
    "y_pred_train = tree_reg.predict(X_train_1)\n",
    "y_pred_validate = tree_reg.predict(X_train_1)\n",
    "\n",
    "# evaluate on validation sete\n",
    "print(\"Error in training set:\")\n",
    "print_eval(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, the decision tree model is performing great - it reaches an RMSE of ~49K on train set, which is much less than the error of the linear regression model (84K). Does this suggest the decision tree is a better fit for the problem?\n",
    "\n",
    "Not at all! If we evaluate the model on new data, we will soon see that the RMSE is much higher (_~104K_) than in training set. This is a sign of the model being severely **overfit**, and likely to **perform bad on future data**.\n",
    "\n",
    "One popular way to evaluate a model is **cross-validation**, which we will try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [104657.89001527 109623.56773174 108277.63146136 108692.00323851\n",
      " 107907.16873381 109107.99605406 110096.13864112 105161.92191748\n",
      " 105958.2773545  106639.09809206]\n",
      "Mean: 107,612\n",
      "Standard deviation: 1,805\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "scores = cross_val_score(tree_reg, X_train_1, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: {:,.0f}\".format(scores.mean()))\n",
    "    print(\"Standard deviation: {:,.0f}\".format(scores.std()))\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation gives an average error of ~108K, which is far more than on the training set (49K). We can expect our decision tree model will give a RMSE of ~108K on future data.\n",
    "\n",
    "Also note that decision tree performs worse than the simple linear regression problem - can you prove that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "1. Use cross validation to build and evaluate a linear regression model. What is the average RMSE?\n",
    "2. Does the linear regression model overfit? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [83577.42916677 84437.91218285 83101.60275605 83722.9528075\n",
      " 86459.93998787 84550.82568437 81990.1916529  83007.38587775\n",
      " 84477.28858687 81873.13334893]\n",
      "Mean: 83,720\n",
      "Standard deviation: 1,288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lin_reg = LinearRegression()\n",
    "scores = cross_val_score(lin_reg, X_train_1, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the question: what can we do to prevent overfitting? There are several ways:\n",
    "\n",
    "1. Obtain more data (again!) \n",
    "2. Regularization\n",
    "3. Tune the hyperparameter(s) of a model with validation set\n",
    "\n",
    "We will cover more in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Build an ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition: each model has its own assumption and pros & cons. They make different types of errors.\n",
    "\n",
    "How about we train a lot of models and combine them together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first ensemble model we use is the imfamous Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average target in train set: 207,202\n",
      "Mean Absolute Error on train set: 38,974\n",
      "Root Mean Squared Error on train set: 55,385\n",
      "Relative Root Mean Squared Error on train set: 26.73 %\n",
      "R^2 of train set: 0.77\n",
      "Scores:  [95499.71334037 98435.11170061 97526.85597194 96345.00069502\n",
      " 95472.1373001 ]\n",
      "Mean: 96,656\n",
      "Standard deviation: 1,163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# train the model\n",
    "forest_reg = RandomForestRegressor(n_estimators=100)\n",
    "forest_reg.fit(X_train_1, y_train)\n",
    "\n",
    "# Evaluate on train set\n",
    "forest_pred = forest_reg.predict(X_train_1)\n",
    "print_eval(y_train, forest_pred)\n",
    "\n",
    "# Also Evaluate using cross-validation\n",
    "scores = cross_val_score(forest_reg, X_train_1, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the training error (55K) is much lower than on validation set (average 97k), indicating overfitting. However, it is better than decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3: Better feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous attempts, we used only 1 feature, the `median_income`. Obviously we have more than that - for example `latitude` and `total_rooms`. Will they give our models a boost?\n",
    "\n",
    "Let's try a no-brainer's approach - feed all avaiable features into the models and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "X_train_2 = X_train.drop(\"ocean_proximity\", axis=1)  # drop ocean_proximity as we do not know what to do with text yet\n",
    "X_train_2 = num_pipeline.fit_transform(X_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [70703.5121299  69136.04055233 70473.48048049 68426.90344941\n",
      " 69931.40885099]\n",
      "Mean: 69,734\n",
      "Standard deviation: 848\n"
     ]
    }
   ],
   "source": [
    "# Linear model, with 5-fold cross validation\n",
    "linear_reg = LinearRegression()\n",
    "scores = cross_val_score(linear_reg, X_train_2, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "linear_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(linear_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [71478.9896855  70766.52566779 69600.65442669 69501.3704902\n",
      " 70206.15310401]\n",
      "Mean: 70,311\n",
      "Standard deviation: 741\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model, with 5-fold cross validation\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "scores = cross_val_score(dt_reg, X_train_2, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "dt_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(dt_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [49611.99457775 50192.20650953 48746.97631491 49079.65178797\n",
      " 49204.1081918 ]\n",
      "Mean: 49,367\n",
      "Standard deviation: 497\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model, with 5-fold cross validation\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "scores = cross_val_score(rf_reg, X_train_2, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the improvement in RMSE?\n",
    "1. Linear model: 84K -> 70K\n",
    "2. Linear model: 108K -> 70K\n",
    "3. Linear model: 97K -> 49K\n",
    "\n",
    "Looks great! By simply feeding more features into the model, we significantly improve our model! But veterans like us should not settle here.\n",
    "\n",
    "Let's try custom-craft some features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train.copy()\n",
    "X_train_3[\"rooms_per_household\"] = X_train_3[\"total_rooms\"]/X_train_3[\"households\"]\n",
    "X_train_3[\"bedrooms_per_room\"] = X_train_3[\"total_bedrooms\"]/X_train_3[\"total_rooms\"]\n",
    "X_train_3[\"population_per_household\"]=X_train_3[\"population\"]/X_train_3[\"households\"]\n",
    "#X_train_3.drop(['households', 'total_rooms', 'ocean_proximity'], axis=1, inplace=True)\n",
    "X_train_3.drop(['ocean_proximity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "X_train_3 = num_pipeline.fit_transform(X_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model:\n",
      "\n",
      "Scores:  [69524.4571517  68557.37806979 69443.0003564  67082.90748632\n",
      " 69180.52607359]\n",
      "Mean: 68,758\n",
      "Standard deviation: 903\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "Scores:  [74662.87003119 71975.9785406  74251.91751703 75535.1100789\n",
      " 70946.99574858]\n",
      "Mean: 73,475\n",
      "Standard deviation: 1,726\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "Scores:  [50911.61823286 50424.01212084 50035.26505469 50975.20645513\n",
      " 51080.4242722 ]\n",
      "Mean: 50,685\n",
      "Standard deviation: 396\n"
     ]
    }
   ],
   "source": [
    "# Linear model, with 5-fold cross validation\n",
    "linear_reg = LinearRegression()\n",
    "scores = cross_val_score(linear_reg, X_train_3, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "linear_rmse_scores = np.sqrt(-scores)\n",
    "print(\"Linear model:\\n\")\n",
    "display_scores(linear_rmse_scores)\n",
    "\n",
    "# Decision Tree model, with 5-fold cross validation\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "scores = cross_val_score(dt_reg, X_train_3, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "dt_rmse_scores = np.sqrt(-scores)\n",
    "print(\"\\nDecision Tree:\\n\")\n",
    "display_scores(dt_rmse_scores)\n",
    "\n",
    "# Random Forest model, with 5-fold cross validation\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "scores = cross_val_score(rf_reg, X_train_3, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "print(\"\\nRandom Forest:\\n\")\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, having these new features does not seem to improve our models much for now. However, in reality the major difference between a good and a bad model is how well the feature engineering step is, as we will soon see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can try tuning the hyperparameters of the models and see what combination lead to the best result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'bootstrap': [True, False], 'max_features': [2, 4, 6],\n",
       "                          'n_estimators': [50, 100, 150]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "{'n_estimators': [50, 100, 150], 'max_features': [2, 4, 6], 'bootstrap': [True, False]},\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "                      max_features=4, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52730.53846386389 {'bootstrap': True, 'max_features': 2, 'n_estimators': 50}\n",
      "52772.665190864354 {'bootstrap': True, 'max_features': 2, 'n_estimators': 100}\n",
      "52418.06915752724 {'bootstrap': True, 'max_features': 2, 'n_estimators': 150}\n",
      "50701.26504097175 {'bootstrap': True, 'max_features': 4, 'n_estimators': 50}\n",
      "50217.27652248249 {'bootstrap': True, 'max_features': 4, 'n_estimators': 100}\n",
      "50287.52596649337 {'bootstrap': True, 'max_features': 4, 'n_estimators': 150}\n",
      "50817.6338655036 {'bootstrap': True, 'max_features': 6, 'n_estimators': 50}\n",
      "50489.717947683064 {'bootstrap': True, 'max_features': 6, 'n_estimators': 100}\n",
      "50315.93951622703 {'bootstrap': True, 'max_features': 6, 'n_estimators': 150}\n",
      "51889.26069221178 {'bootstrap': False, 'max_features': 2, 'n_estimators': 50}\n",
      "51573.456594402254 {'bootstrap': False, 'max_features': 2, 'n_estimators': 100}\n",
      "51438.598905660154 {'bootstrap': False, 'max_features': 2, 'n_estimators': 150}\n",
      "49797.90270790439 {'bootstrap': False, 'max_features': 4, 'n_estimators': 50}\n",
      "49515.283688976946 {'bootstrap': False, 'max_features': 4, 'n_estimators': 100}\n",
      "49236.02211794524 {'bootstrap': False, 'max_features': 4, 'n_estimators': 150}\n",
      "50268.58905367176 {'bootstrap': False, 'max_features': 6, 'n_estimators': 50}\n",
      "49856.96061337256 {'bootstrap': False, 'max_features': 6, 'n_estimators': 100}\n",
      "49771.406207509695 {'bootstrap': False, 'max_features': 6, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination `{'bootstrap': False, 'max_features': 4, 'n_estimators': 150}` performs best with RMSE of 49K. In reality, we will do more searches to seek the best combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing model performance:\n",
    "\n",
    "| Model      |# features used | Cross-validation RMSE |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Linear      | 1       |84K|\n",
    "| Decision Tree   | 1        |108K|\n",
    "| Random Forest   | 1        |97K|\n",
    "| Linear      | 8       |70K|\n",
    "| Decision Tree   | 8        |70K|\n",
    "| Random Forest   | 8        |49K|\n",
    "| Linear      | 12       |69K|\n",
    "| Decision Tree   | 12        |73K|\n",
    "| Random Forest   | 12        |51K|\n",
    "| Random Forest (with grid search)  | 12        |49K|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last method, as always, is to get more data (either in volumn or diversity). I will leave this as your exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
